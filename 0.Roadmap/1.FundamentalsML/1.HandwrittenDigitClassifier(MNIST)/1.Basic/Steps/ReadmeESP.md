<h1 align="center"  style="margin-bottom: -10px;"> House Price Prediction with Machine Learning </h1>
<div align="center">

 Este README est谩 disponible en: [Ingl茅s](Readme.md) | [Espa帽ol](ReadmeESP.md) 

</div>

<h2 align="center"> Table of Contents</h2>

1. [Descripci贸n](#descripcion)
2. [Proceso de Desarrollo](#desarollo)
   - [1.1.Procesamiento de Datos](#datos)
      - [1.1.1.Carga de datos](#Cdatos)
      - [1.1.2.Explorando las dimensiones del conjunto de datos](#Nvalues)
      - [1.1.3 N煤mero de ejemplos por clase](#Dduplicados)
   - [1.2.An谩lisis Exploratorio de Datos (EDA)](#eda)
      - [1.2.1.Distribuci贸n de clases](#heatmap)
      - [1.2.2.Ejemplos de las clases](#pairplot)
      - [1.2.3.Normalizamos los datos](#desc)
    - [1.3 Entrenamiento de M煤ltiples Algoritmos](#Malgoritmos)
    - [1.4 M茅tricas de Evaluaci贸n](#metricas)
    - [1.5 Optimizaci贸n (Ajuste y Hiperpar谩metros)](#optimizacion)
    - [1.6 Agrupar (1/2)](#agrupar1)
    - [1.7 Personalizaci贸n](#perso1)
    - [1.8 Join all (2/2)](#join2)
4. [Resultados Finales](#resultados)
5. [Tecnolog铆as Utilizadas](#tech)
6. [C贸mo Ejecutar](#ejecutar)

<h2 id="descripcion" align="center"> Descripci贸n </h2>

Este es un proyecto de clasificaci贸n en el que se implementa una pipeline completa de Machine Learning (excepto la etapa de data augmentation) para clasificar d铆gitos escritos a mano. Cabe destacar que se trabaja con im谩genes, por lo que el modelo debe predecir el valor num茅rico representado visualmente.

A continuaci贸n, se explican cada uno de los pasos seguidos para resolver el problema, detallando la l贸gica aplicada en cada etapa del proceso.

<h2 id="desarollo" align="center">Proceso de Desarrollo</h2>

<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; vertical-align: top; text-align: left; padding-right: 20px;">
    El desarrollo de este proyecto sigue una estructura l贸gica por etapas que permite construir un modelo de clasificaci贸n robusto y comprensible. <br>
    Comenzamos con la carga y preparaci贸n de los datos, seguidos de un an谩lisis exploratorio para entender mejor la distribuci贸n de clases y el contenido visual del dataset. <br>
    Luego, se entrenan m煤ltiples algoritmos de clasificaci贸n con el fin de comparar su rendimiento utilizando m茅tricas adecuadas.
    En la etapa de evaluaci贸n, utilizamos estas m茅tricas para seleccionar el modelo con mejor desempe帽o.
    Posteriormente, optimizamos los modelos para mejorar sus resultados y predicciones. <br>
    Una vez finalizado este proceso, integramos todo el flujo de trabajo en un programa unificado y funcional.
    Finalmente, realizamos pruebas utilizando el modelo entrenado y visualizamos los resultados en un dashboard.
    </td>
    <td style="width: 50%;">
      <img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/Spanish.png?raw=true" alt="Dashboard Preview" style="width: 100%; height: auto;" />
    </td>
  </tr>
</table>

<h3 id="desarollo" align="center">1.1 Procesamiento de Datos</h3>


<h4 id="Cdatos" align="center">1.1.1 Carga de datos</h4>

En este primer paso, cargamos el conjunto de datos que utilizaremos a lo largo del proyecto. Espec铆ficamente, empleamos el dataset load_digits, el cual es proporcionado por la librer铆a sklearn.datasets.
Este dataset es ampliamente utilizado como punto de partida para tareas de clasificaci贸n de im谩genes debido a su tama帽o manejable y su formato estandarizado.

En esta etapa, tambi茅n separamos los datos en dos variables principales:

**X**: que contiene las representaciones num茅ricas (flattened) de las im谩genes.
**y**: que contiene las etiquetas correspondientes a cada imagen, indicando el d铆gito que representa (del 0 al 9).

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/1.LoadData/1.0.png?raw=true" alt="Dashboard Preview" style="width: 100%; height: auto;" />

>[!NOTE]
>Este dataset nos permite entrenar y evaluar modelos de forma r谩pida sin necesidad de preprocesamiento complejo o recursos computacionales intensivos.


<h4 id="Nvalues" align="center">1.1.2 Explorando las dimensiones del conjunto de datos</h4>

A continuaci贸n, verificamos cu谩ntas muestras tenemos disponibles en las variables X e y, asegur谩ndonos de que ambas tengan la misma cantidad de elementos, lo cual es fundamental para el entrenamiento del modelo.

La variable X representa los datos de entrada, es decir, los valores de intensidad de los p铆xeles de cada imagen. Cada imagen ha sido transformada en un vector unidimensional de 64 elementos (8x8), lo que permite que los algoritmos de Machine Learning puedan procesarlas como datos num茅ricos.

Por otro lado, la variable y contiene las etiquetas o valores objetivo, que indican el n煤mero que representa cada imagen (del 0 al 9). Estas etiquetas servir谩n como referencia durante el entrenamiento, permitiendo al modelo aprender a reconocer y clasificar los patrones visuales que caracterizan a cada d铆gito.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/1.LoadData/1.1.png?raw=true" alt="Dashboard Preview" style="width: 100%; height: auto;" />


<h4 id="Dduplicados" align="center">1.1.3 N煤mero de ejemplos por clase </h4>


Finalmente, analizamos las clases presentes en el conjunto de datos, as铆 como la cantidad de ejemplos disponibles para cada una de ellas. Este an谩lisis nos permite entender la distribuci贸n general del dataset y detectar posibles desequilibrios entre clases, lo cual es un aspecto crucial en los problemas de clasificaci贸n.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/1.LoadData/1.2.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;">

<h3 id="eda" align="center">1.2 Exploratory Data Analysis (EDA)</h3>

<h4 id="heatmap" align="center">1.2.1 Distribuci贸n de clases</h4>

Como primer paso en el an谩lisis exploratorio, es importante visualizar gr谩ficamente la distribuci贸n de los datos para identificar cu谩ntos ejemplos existen por clase. Esta representaci贸n nos permite observar de forma clara si alguna clase est谩 desbalanceada, es decir, si hay d铆gitos que aparecen con mayor o menor frecuencia en comparaci贸n con otros.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/2.DataPreprocessing/2.1.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;">


<h4 id="pairplot" align="center">1.2.2 Ejemplos de las clases</h4>

A continuaci贸n, observaremos algunos ejemplos visuales de cada una de las clases presentes en el dataset. El objetivo de esta visualizaci贸n es comprender c贸mo se representan gr谩ficamente los d铆gitos y qu茅 tipo de variaciones pueden existir dentro de una misma clase.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/2.DataPreprocessing/2.2.png?raw=true?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;">

Esto nos permite tener una mejor idea de los patrones que el modelo deber谩 aprender a detectar y clasificar, considerando que los datos escritos a mano pueden presentar diferencias en forma, tama帽o y estilo seg煤n cada muestra.

<h4 id="desc" align="center">1.2.3.Normalizamos los datos</h4>

Observamos que la distribuci贸n de clases en el conjunto de datos es bastante uniforme, es decir, el n煤mero de ejemplos por clase es similar. Gracias a este balance, no es necesario aplicar t茅cnicas adicionales de balanceo o muestreo.

Por lo tanto, el 煤nico paso previo al entrenamiento de los modelos que consideramos necesario en esta etapa es la normalizaci贸n de los datos. Este proceso ajusta la escala de los valores de entrada, facilitando el aprendizaje de los algoritmos y mejorando su rendimiento y estabilidad.


<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/2.DataPreprocessing/2.3.png?raw=true?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;">

<h3 id="Malgoritmos" align="center">1.3.Training Multiple Algorithms</h3>

Pasamos a la etapa de entrenamiento del modelo, donde aplicaremos diferentes algoritmos de clasificaci贸n para comparar su rendimiento.
Dado que se trata de un problema de clasificaci贸n, se entrenar谩n los siguientes modelos:

- Logistic Regression
- K-Nearest Neighbors (KNN)
- Support Vector Machine (SVM)
- Multi-Layer Perceptron (MLP)

El objetivo de este paso es evaluar cu谩l modelo se adapta mejor a los datos, considerando m茅tricas de desempe帽o, interpretabilidad y complejidad computacional.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/3.training/3.2.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;">

<h3 id="metricas" align="center">1.4.M茅tricas de Evaluaci贸n</h3>

Tras evaluar el rendimiento de todos los modelos, observamos algo curioso: todos alcanzaron el mismo nivel de precisi贸n (accuracy), lo que sugiere que cualquiera de ellos podr铆a funcionar correctamente. Por lo tanto, a煤n no se ha seleccionado un modelo definitivo.

<br>
<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/4.EvaluationM/4.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;"> 

<h3 id="optimizacion" align="center">1.5.Optimization (Tuning & Hyperparameters)</h3>

Al optimizar todos los modelos, me percat茅 de que dos de ellos mostraron una mejora significativa en su desempe帽o: Support Vector Machine (SVM) y Multi-layer Perceptron (MLP). Ambos modelos lograron superar a los dem谩s en t茅rminos de precisi贸n y estabilidad durante las pruebas. Sin embargo, considerando factores como la complejidad computacional, la interpretabilidad y el tiempo de entrenamiento, optaremos por utilizar el modelo SVM como el modelo final para este proyecto.
 
<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/5.Optimization/5.6.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;"> 

<h3 id="optimizacion" align="center">1.6.Agrupar (1/2)</h3>

En este paso, nos enfocamos en presentar visualmente los elementos m谩s relevantes del programa, eliminando aquellos modelos, m茅tricas y componentes que ya no son necesarios para simplificar el an谩lisis.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/6.JoinAll/5.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;"> 

<h3 id="perso1" align="center">1.7 Personalizaci贸n</h3>
Para el desarrollo del dashboard, utilic茅 la librer铆a Streamlit y elabor茅 un boceto inicial con el prop贸sito de definir la estructura visual y funcional del proyecto antes de proceder con su implementaci贸n.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/7Personalization/7.1.jpeg?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;"> 

<h3 id="join2" align="center">1.8 Join All (2/2)</h3>
En este paso, realizamos una prueba completa del dashboard para asegurarnos de que todos los elementos est茅n correctamente alineados, funcionando como se espera y que la interfaz se muestre de forma ordenada
<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/7Personalization/Dashboard.jpeg?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;"> 


<h2 id="resultados" align="center">3.Resultados Finales</h2>

 Dataset utilizado: `load_digits`, proporcionado por la librer铆a [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) *(disponible en sklearn.datasets)*
 Tipo de aprendizaje: Supervisado
 Tipo de problema: Clasificaci贸n
锔 Algoritmo principal: SVM
И Nivel del modelo: B谩sico
 Lenguaje utilizado: Python
 Tipo de proyecto: Personal / Portafolio

<h2 id="tech" align="center">4.Tecnolog铆as Utilizadas</h2>

 Manipulaci贸n y an谩lisis de datos

- pandas
- numpy

 Visualizaci贸n

- matplotlib
- seaborn
- pillow

 Machine Learning

- scikit-learn

 Desarrollo de aplicaciones
- streamlit

<h2 id="ejecutar" align="center">5.Como Ejecutar el programa</h2>

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/Program.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;">

```bash
git clone https://github.com/KevinAlberto01/3.MachineLearning.git
cd 3.MachineLearning/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Local/
1.Basic/Local
python 0.LOGICA.py
```

>[!IMPORTANT]
>Estos comandos se utilizan exclusivamente para ejecutar la l贸gica del programa, incluyendo el flujo de trabajo de Machine Learning.


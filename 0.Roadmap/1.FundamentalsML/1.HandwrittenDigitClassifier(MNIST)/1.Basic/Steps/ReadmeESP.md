<h1 align="center"  style="margin-bottom: -10px;">游 House Price Prediction with Machine Learning 游</h1>
<div align="center">

游깷 Este README est치 disponible en: [Ingl칠s](Readme.md) | [Espa침ol](ReadmeESP.md) 游깷

</div>

<h2 align="center">游늼 Table of Contents</h2>

1. [Descripci칩n](#descripcion)
2. [Proceso de Desarrollo](#desarollo)
   - [1.1.Procesamiento de Datos](#datos)
      - [1.1.1.Carga de datos](#Cdatos)
      - [1.1.2.Explorando las dimensiones del conjunto de datos](#Nvalues)
      - [1.1.3 N칰mero de ejemplos por clase](#Dduplicados)
   - [1.2.An치lisis Exploratorio de Datos (EDA)](#eda)
      - [1.2.1.Distribuci칩n de clases](#heatmap)
      - [1.2.2.Ejemplos de las clases](#pairplot)
      - [1.2.3.Normalizamos los datos](#desc)
    - [1.3 Entrenamiento de M칰ltiples Algoritmos](#Malgoritmos)
    - [1.4 M칠tricas de Evaluaci칩n](#metricas)
    - [1.5 Optimizaci칩n (Ajuste y Hiperpar치metros)](#optimizacion)
    - [1.6 Agrupar (1/2)](#agrupar1)
    - [1.7 Personalizaci칩n](#perso1)
    - [1.8 Join all (2/2)](#join2)
4. [Resultados Finales](#resultados)
5. [Tecnolog칤as Utilizadas](#tech)
6. [C칩mo Ejecutar](#ejecutar)

<h2 id="descripcion" align="center">游닆 Descripci칩n 游닆</h2>

Este es un proyecto de clasificaci칩n en el que se implementa una pipeline completa de Machine Learning (excepto la etapa de data augmentation) para clasificar d칤gitos escritos a mano. Cabe destacar que se trabaja con im치genes, por lo que el modelo debe predecir el valor num칠rico representado visualmente.

A continuaci칩n, se explican cada uno de los pasos seguidos para resolver el problema, detallando la l칩gica aplicada en cada etapa del proceso.

<h2 id="desarollo" align="center">Proceso de Desarrollo</h2>

<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; vertical-align: top; text-align: left; padding-right: 20px;">
    El desarrollo de este proyecto sigue una estructura l칩gica por etapas que permite construir un modelo de clasificaci칩n robusto y comprensible. <br>
    Comenzamos con la carga y preparaci칩n de los datos, seguidos de un an치lisis exploratorio para entender mejor la distribuci칩n de clases y el contenido visual del dataset. <br>
    Luego, se entrenan m칰ltiples algoritmos de clasificaci칩n con el fin de comparar su rendimiento utilizando m칠tricas adecuadas.
    En la etapa de evaluaci칩n, utilizamos estas m칠tricas para seleccionar el modelo con mejor desempe침o.
    Posteriormente, optimizamos los modelos para mejorar sus resultados y predicciones. <br>
    Una vez finalizado este proceso, integramos todo el flujo de trabajo en un programa unificado y funcional.
    Finalmente, realizamos pruebas utilizando el modelo entrenado y visualizamos los resultados en un dashboard.
    </td>
    <td style="width: 50%;">
      <img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/Spanish.png?raw=true" alt="Dashboard Preview" style="width: 100%; height: auto;" />
    </td>
  </tr>
</table>

<h3 id="desarollo" align="center">1.1 Procesamiento de Datos</h3>


<h4 id="Cdatos" align="center">1.1.1 Carga de datos</h4>

En este primer paso, cargamos el conjunto de datos que utilizaremos a lo largo del proyecto. Espec칤ficamente, empleamos el dataset load_digits, el cual es proporcionado por la librer칤a sklearn.datasets.
Este dataset es ampliamente utilizado como punto de partida para tareas de clasificaci칩n de im치genes debido a su tama침o manejable y su formato estandarizado.

En esta etapa, tambi칠n separamos los datos en dos variables principales:

**X**: que contiene las representaciones num칠ricas (flattened) de las im치genes.
**y**: que contiene las etiquetas correspondientes a cada imagen, indicando el d칤gito que representa (del 0 al 9).

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/1.LoadData/1.0.png?raw=true" alt="Dashboard Preview" style="width: 100%; height: auto;" />

>[!NOTE]
>Este dataset nos permite entrenar y evaluar modelos de forma r치pida sin necesidad de preprocesamiento complejo o recursos computacionales intensivos.


<h4 id="Nvalues" align="center">1.1.2 Explorando las dimensiones del conjunto de datos</h4>

A continuaci칩n, verificamos cu치ntas muestras tenemos disponibles en las variables X e y, asegur치ndonos de que ambas tengan la misma cantidad de elementos, lo cual es fundamental para el entrenamiento del modelo.

La variable X representa los datos de entrada, es decir, los valores de intensidad de los p칤xeles de cada imagen. Cada imagen ha sido transformada en un vector unidimensional de 64 elementos (8x8), lo que permite que los algoritmos de Machine Learning puedan procesarlas como datos num칠ricos.

Por otro lado, la variable y contiene las etiquetas o valores objetivo, que indican el n칰mero que representa cada imagen (del 0 al 9). Estas etiquetas servir치n como referencia durante el entrenamiento, permitiendo al modelo aprender a reconocer y clasificar los patrones visuales que caracterizan a cada d칤gito.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/1.LoadData/1.1.png?raw=true" alt="Dashboard Preview" style="width: 100%; height: auto;" />


<h4 id="Dduplicados" align="center">1.1.3 N칰mero de ejemplos por clase </h4>


Finalmente, analizamos las clases presentes en el conjunto de datos, as칤 como la cantidad de ejemplos disponibles para cada una de ellas. Este an치lisis nos permite entender la distribuci칩n general del dataset y detectar posibles desequilibrios entre clases, lo cual es un aspecto crucial en los problemas de clasificaci칩n.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/1.LoadData/1.2.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;">

<h3 id="eda" align="center">1.2 Exploratory Data Analysis (EDA)</h3>

<h4 id="heatmap" align="center">1.2.1 Distribuci칩n de clases</h4>

Como primer paso en el an치lisis exploratorio, es importante visualizar gr치ficamente la distribuci칩n de los datos para identificar cu치ntos ejemplos existen por clase. Esta representaci칩n nos permite observar de forma clara si alguna clase est치 desbalanceada, es decir, si hay d칤gitos que aparecen con mayor o menor frecuencia en comparaci칩n con otros.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/2.DataPreprocessing/2.1.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;">


<h4 id="pairplot" align="center">1.2.2 Ejemplos de las clases</h4>

A continuaci칩n, observaremos algunos ejemplos visuales de cada una de las clases presentes en el dataset. El objetivo de esta visualizaci칩n es comprender c칩mo se representan gr치ficamente los d칤gitos y qu칠 tipo de variaciones pueden existir dentro de una misma clase.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/2.DataPreprocessing/2.2.png?raw=true?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;">

Esto nos permite tener una mejor idea de los patrones que el modelo deber치 aprender a detectar y clasificar, considerando que los datos escritos a mano pueden presentar diferencias en forma, tama침o y estilo seg칰n cada muestra.

<h4 id="desc" align="center">1.2.3.Normalizamos los datos</h4>

Observamos que la distribuci칩n de clases en el conjunto de datos es bastante uniforme, es decir, el n칰mero de ejemplos por clase es similar. Gracias a este balance, no es necesario aplicar t칠cnicas adicionales de balanceo o muestreo.

Por lo tanto, el 칰nico paso previo al entrenamiento de los modelos que consideramos necesario en esta etapa es la normalizaci칩n de los datos. Este proceso ajusta la escala de los valores de entrada, facilitando el aprendizaje de los algoritmos y mejorando su rendimiento y estabilidad.


<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/2.DataPreprocessing/2.3.png?raw=true?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;">

<h3 id="Malgoritmos" align="center">1.3.Training Multiple Algorithms</h3>

Pasamos a la etapa de entrenamiento del modelo, donde aplicaremos diferentes algoritmos de clasificaci칩n para comparar su rendimiento.
Dado que se trata de un problema de clasificaci칩n, se entrenar치n los siguientes modelos:

- Logistic Regression
- K-Nearest Neighbors (KNN)
- Support Vector Machine (SVM)
- Multi-Layer Perceptron (MLP)

El objetivo de este paso es evaluar cu치l modelo se adapta mejor a los datos, considerando m칠tricas de desempe침o, interpretabilidad y complejidad computacional.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/3.training/3.2.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;">

<h3 id="metricas" align="center">1.4.M칠tricas de Evaluaci칩n</h3>

Tras evaluar el rendimiento de todos los modelos, observamos algo curioso: todos alcanzaron el mismo nivel de precisi칩n (accuracy), lo que sugiere que cualquiera de ellos podr칤a funcionar correctamente. Por lo tanto, a칰n no se ha seleccionado un modelo definitivo.

<br>
<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/4.EvaluationM/4.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;"> 

<h3 id="optimizacion" align="center">1.5.Optimization (Tuning & Hyperparameters)</h3>

Al optimizar todos los modelos, me percat칠 de que dos de ellos mostraron una mejora significativa en su desempe침o: Support Vector Machine (SVM) y Multi-layer Perceptron (MLP). Ambos modelos lograron superar a los dem치s en t칠rminos de precisi칩n y estabilidad durante las pruebas. Sin embargo, considerando factores como la complejidad computacional, la interpretabilidad y el tiempo de entrenamiento, optaremos por utilizar el modelo SVM como el modelo final para este proyecto.
 
<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/5.Optimization/5.6.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;"> 

<h3 id="optimizacion" align="center">1.6.Agrupar (1/2)</h3>

En este paso, nos enfocamos en presentar visualmente los elementos m치s relevantes del programa, eliminando aquellos modelos, m칠tricas y componentes que ya no son necesarios para simplificar el an치lisis.

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/6.JoinAll/5.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;"> 

<h3 id="perso1" align="center">1.7 Personalizaci칩n</h3>
Para el desarrollo del dashboard, utilic칠 la librer칤a Streamlit y elabor칠 un boceto inicial con el prop칩sito de definir la estructura visual y funcional del proyecto antes de proceder con su implementaci칩n.

<h3 id="join2" align="center">1.7 Personalizaci칩n</h3>
<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/7Personalization/Dashboard.jpeg?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;"> 


<h2 id="resultados" align="center">4.4.Resultados Finales</h2>

游늭 Dataset utilizado: `load_digits`, proporcionado por la librer칤a [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) *(disponible en sklearn.datasets)*
游 Tipo de aprendizaje: Supervisado
游늳 Tipo de problema: Clasificaci칩n
丘뙖잺 Algoritmo principal: SVM
游빍 Nivel del modelo: B치sico
游눹 Lenguaje utilizado: Python
游녻 Tipo de proyecto: Personal / Portafolio

<h2 id="tech" align="center">5.Tecnolog칤as Utilizadas</h2>

游늵 Manipulaci칩n y an치lisis de datos

- pandas
- numpy

游늳 Visualizaci칩n

- matplotlib
- seaborn
- pillow

游뱄 Machine Learning

- scikit-learn

游닍 Desarrollo de aplicaciones
- streamlit

<h2 id="ejecutar" align="center">6.Como Ejecutar el programa</h2>

<img src="https://github.com/KevinAlberto01/3.MachineLearning/blob/main/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Steps/img/Program.png?raw=true" alt="Tipos de datos" style="width: 100%; height: auto;">

```bash
git clone https://github.com/KevinAlberto01/3.MachineLearning.git
cd 3.MachineLearning/0.Roadmap/1.FundamentalsML/1.HandwrittenDigitClassifier(MNIST)/1.Basic/Local/
1.Basic/Local
python 0.LOGICA.py
```

>[!IMPORTANT]
>Estos comandos se utilizan exclusivamente para ejecutar la l칩gica del programa, incluyendo el flujo de trabajo de Machine Learning.

